{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f6606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c463a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得某個階段的所有檔名\n",
    "def get_filename(root_dir):\n",
    "    tmp = glob.glob(root_dir + '/*.json')\n",
    "        \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dec8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_numberOfData(files):\n",
    "    for i in tqdm(range(len(files))):\n",
    "        # 讀取原始 json file\n",
    "        f = open(os.path.join(base_path, files[i]))\n",
    "        p = json.load(f)\n",
    "        \n",
    "        for k in p.keys():\n",
    "            try:\n",
    "                keys = list(p[k].keys())\n",
    "                \n",
    "                if len(keys) == 13:\n",
    "                    p[k]['numberOfData'] = 1\n",
    "                elif len(keys) == 14:\n",
    "                    p[k]['numberOfData'] = 2\n",
    "                elif len(keys) == 15:\n",
    "                    p[k]['numberOfData'] = 3\n",
    "                elif len(keys) == 16:\n",
    "                    p[k]['numberOfData'] = 4\n",
    "                elif len(keys) == 17:\n",
    "                    p[k]['numberOfData'] = 5\n",
    "                elif len(keys) == 18:\n",
    "                    p[k]['numberOfData'] = 6\n",
    "                elif len(keys) == 19:\n",
    "                    p[k]['numberOfData'] = 7\n",
    "                elif len(keys) == 20:\n",
    "                    p[k]['numberOfData'] = 8\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        # 刪除原始 json file\n",
    "        os.remove(os.path.join(base_path, files[i]))\n",
    "        \n",
    "        # Write into new json file\n",
    "        with open(os.path.join(base_path, files[i]), 'w') as file:\n",
    "            json.dump(p, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939d96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_json(files):\n",
    "    for i in tqdm(range(len(files))):\n",
    "        # 讀取原始 json file\n",
    "        f = open(os.path.join(base_path, files[i]))\n",
    "        p = json.load(f)\n",
    "        \n",
    "        # 新增 primary key 欄位\n",
    "        month = int(files[i][:2]) - 12\n",
    "        month = str(month) if month/10==1 else '0'+str(month)\n",
    "        version = files[i][-7]\n",
    "        p['event'] = year[-2:] + str(month) + files[i][2:8] + version\n",
    "        for k in p.keys():\n",
    "            try:\n",
    "                if 'location' in p[k].keys():\n",
    "                    # 看有幾組資料\n",
    "                    n_data = len(p[k]['location'])\n",
    "                    output_dict = {}\n",
    "                    p[k]['numberOfData'] = n_data\n",
    "                    \n",
    "                    # 逐一拿出資料\n",
    "                    for n in range(n_data):\n",
    "                        tmp_dict = {}\n",
    "                        tmp_dict['network'] = p[k]['network'][n]\n",
    "                        tmp_dict['location'] = p[k]['location'][n]\n",
    "                        tmp_dict['factor'] = p[k]['factor'][n]\n",
    "                        tmp_dict['sampling_rate'] = p[k]['sampling_rate'][n]\n",
    "                        tmp_dict['starttime'] = p[k]['starttime'][n]\n",
    "                        tmp_dict['endtime'] = p[k]['endtime'][n]\n",
    "                        tmp_dict['instrument'] = p[k]['instrument'][n]\n",
    "                        tmp_dict['datatype'] = p[k]['datatype'][n]\n",
    "                        if n_data > 1:\n",
    "                            tmp_dict['Z'], tmp_dict['N'], tmp_dict['E'] = p[k]['Z'][n], p[k]['N'][n], p[k]['E'][n]\n",
    "                        else:\n",
    "                            tmp_dict['Z'], tmp_dict['N'], tmp_dict['E'] = p[k]['Z'], p[k]['N'], p[k]['E']\n",
    "                        tmp_dict['pga'], tmp_dict['pgv'] = p[k]['pga'][n], p[k]['pgv'][n]\n",
    "                        tmp_dict['p_arrival_time'], tmp_dict['s_arrival_time'] = p[k]['p_arrival_time'][n], p[k]['s_arrival_time'][n]\n",
    "                        tmp_dict['intensity'] = p[k]['intensity'][n]\n",
    "                        tmp_dict['DataAvailable'] = {}\n",
    "                        for key in p[k]['DataAvailable'].keys():\n",
    "                            tmp_dict['DataAvailable'][key] = p[k]['DataAvailable'][key][n]\n",
    "                            \n",
    "                        # 新增到依順序建立的新 key\n",
    "                        output_dict[str(n)] = tmp_dict\n",
    "                            \n",
    "                    # 刪除要改掉的 keys\n",
    "                    del p[k]['network'], p[k]['location'], p[k]['factor'], p[k]['sampling_rate'], p[k]['starttime']\n",
    "                    del p[k]['endtime'], p[k]['instrument'], p[k]['datatype'], p[k]['Z'], p[k]['N'], p[k]['E']\n",
    "                    del p[k]['pga'], p[k]['pgv'], p[k]['p_arrival_time'], p[k]['s_arrival_time']\n",
    "                    del p[k]['intensity'], p[k]['DataAvailable']\n",
    "                            \n",
    "                    # 把改好的加進原始資料中\n",
    "                    for modify_k in output_dict.keys():\n",
    "                        p[k][modify_k] = output_dict[modify_k]\n",
    "                        \n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                pass\n",
    "            \n",
    "        # 刪除原始 json file\n",
    "        os.remove(os.path.join(base_path, files[i]))\n",
    "        \n",
    "        # Write into new json file\n",
    "        with open(os.path.join(base_path, files[i]), 'w') as file:\n",
    "            json.dump(p, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65956ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 564/564 [3:06:13<00:00, 19.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# target: 2020, 2019, 2018, 2017, 2016, 2015. 2014\n",
    "#all_year = ['2020', '2019', '2018', '2017', '2016', '2015', '2014']\n",
    "all_year = ['2019']\n",
    "for year in all_year:\n",
    "    sub_fname = year[2:]\n",
    "    base_path = os.path.join('/mnt/nas6/CWBSN', year)\n",
    "    files = os.listdir(base_path)\n",
    "    \n",
    "    modify_json(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b805d9",
   "metadata": {},
   "source": [
    "## modify primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "566a5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n",
    "year = '2013'\n",
    "root = \"/mnt/nas6/CWBSN/\"+year\n",
    "files = get_filename(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6b17cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1168/1168 [2:16:13<00:00,  7.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    try:\n",
    "        f = open(os.path.join(root, file), 'r')\n",
    "        p = json.load(f)\n",
    "\n",
    "        month = int(file[-16:-14])-12\n",
    "        month = str(month) if month//10==1 else '0'+str(month)\n",
    "        pk = year[-2:]+month+file[-14:-8]+file[-7]\n",
    "        p['event'] = pk\n",
    "\n",
    "        os.remove(os.path.join(root, file))\n",
    "        with open(os.path.join(root, file), 'w') as f:\n",
    "            json.dump(p, f)\n",
    "    except:\n",
    "        with open('/mnt/nas6/CWBSN/modifyPK_2013.txt', 'w') as f:\n",
    "            f.write(file+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa566ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(root, files[1]), 'r')\n",
    "p = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "371457db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas6/CWBSN/2013/15201638(0).json'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe2788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earthworm",
   "language": "python",
   "name": "earthworm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
