{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4f628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ad9d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_json(files):\n",
    "    for i in tqdm(range(len(files))):\n",
    "        # 讀取原始 json file\n",
    "        f = open(os.path.join(base_path, files[i]))\n",
    "        p = json.load(f)\n",
    "        \n",
    "        # 刪除原始 json file\n",
    "        #os.remove(os.path.join(base_path, files[i]))\n",
    "        \n",
    "        # 新增 primary key 欄位\n",
    "        month = int(files[i][:2]) - 12\n",
    "        version = files[i][-7]\n",
    "        p['event'] = year[-2:] + str(month) + files[i][2:8] + version\n",
    "        for k in p.keys():\n",
    "            try:\n",
    "                if 'location' in p[k].keys():\n",
    "                    # 看有幾組資料\n",
    "                    n_data = len(p[k]['location'])\n",
    "                    output_dict = {}\n",
    "                    \n",
    "                    # 逐一拿出資料\n",
    "                    for n in range(n_data):\n",
    "                        tmp_dict = {}\n",
    "                        tmp_dict['network'] = p[k]['network'][n]\n",
    "                        tmp_dict['location'] = p[k]['location'][n]\n",
    "                        tmp_dict['factor'] = p[k]['factor'][n]\n",
    "                        tmp_dict['sampling_rate'] = p[k]['sampling_rate'][n]\n",
    "                        tmp_dict['starttime'] = p[k]['starttime'][n]\n",
    "                        tmp_dict['endtime'] = p[k]['endtime'][n]\n",
    "                        tmp_dict['instrument'] = p[k]['instrument'][n]\n",
    "                        tmp_dict['datatype'] = p[k]['datatype'][n]\n",
    "                        if n_data > 1:\n",
    "                            tmp_dict['Z'], tmp_dict['N'], tmp_dict['E'] = p[k]['Z'][n], p[k]['N'][n], p[k]['E'][n]\n",
    "                        else:\n",
    "                            tmp_dict['Z'], tmp_dict['N'], tmp_dict['E'] = p[k]['Z'], p[k]['N'], p[k]['E']\n",
    "                        tmp_dict['pga'], tmp_dict['pgv'] = p[k]['pga'][n], p[k]['pgv'][n]\n",
    "                        tmp_dict['p_arrival_time'], tmp_dict['s_arrival_time'] = p[k]['p_arrival_time'][n], p[k]['s_arrival_time'][n]\n",
    "                        tmp_dict['intensity'] = p[k]['intensity'][n]\n",
    "                        tmp_dict['DataAvailable'] = {}\n",
    "                        for key in p[k]['DataAvailable'].keys():\n",
    "                            tmp_dict['DataAvailable'][key] = p[k]['DataAvailable'][key][n]\n",
    "                            \n",
    "                        # 新增到依順序建立的新 key\n",
    "                        output_dict[str(n)] = tmp_dict\n",
    "                            \n",
    "                    # 刪除要改掉的 keys\n",
    "                    del p[k]['network'], p[k]['location'], p[k]['factor'], p[k]['sampling_rate'], p[k]['starttime']\n",
    "                    del p[k]['endtime'], p[k]['instrument'], p[k]['datatype'], p[k]['Z'], p[k]['N'], p[k]['E']\n",
    "                    del p[k]['pga'], p[k]['pgv'], p[k]['p_arrival_time'], p[k]['s_arrival_time']\n",
    "                    del p[k]['intensity'], p[k]['DataAvailable']\n",
    "                            \n",
    "                    # 把改好的加進原始資料中\n",
    "                    for modify_k in output_dict.keys():\n",
    "                        p[k][modify_k] = output_dict[modify_k]\n",
    "                        \n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                pass\n",
    "        # Write into new json file\n",
    "        #with open(os.path.join(base_path, files[i]), 'w') as file:\n",
    "        with open('/mnt/nas6/CWBDatasets/test.json', 'w') as file:\n",
    "            json.dump(p, file)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e51c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish: 2020, 2019\n",
    "year = '2020'\n",
    "sub_fname = year[2:]\n",
    "base_path = os.path.join('/mnt/nas6/CWBDatasets', year)\n",
    "files = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c0bb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                           | 0/509 [00:40<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "modify_json(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3302b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earthworm",
   "language": "python",
   "name": "earthworm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
